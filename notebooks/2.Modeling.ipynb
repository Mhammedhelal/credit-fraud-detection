{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f779d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.pipeline import Pipeline as imb_Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ff0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "val = pd.read_csv('../data/val.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_stats(train_df):\n",
    "    stats = {}\n",
    "    \n",
    "    # amount stats\n",
    "    stats['log_amount_mean'] = np.mean(np.log1p(train_df['Amount']))\n",
    "    stats['log_amount_std']  = np.std(np.log1p(train_df['Amount']))\n",
    "    \n",
    "    # amount bins (quantiles)\n",
    "    stats['amount_bins'] = pd.qcut(\n",
    "        np.log1p(train_df['Amount']),\n",
    "        q=5,\n",
    "        retbins=True\n",
    "    )[1]  \n",
    "    \n",
    "    return stats\n",
    "\n",
    "def apply_feature_engineering(data, train_stats=None):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # 1. Hour + rush hour\n",
    "    df['Hour'] = (df['Time'] // 3600) % 24\n",
    "    df['is_rush_hour'] = df['Hour'].apply(lambda h: 1 if h in [0,1,2] else 0)\n",
    "\n",
    "    # 2. log amount\n",
    "    df['log_amount'] = np.log1p(df['Amount'])\n",
    "    \n",
    "    # --- if train: calculate stats ---\n",
    "    if train_stats is None:\n",
    "        train_stats = {}\n",
    "        train_stats['log_amount_mean'] = df['log_amount'].mean()\n",
    "        train_stats['log_amount_std'] = df['log_amount'].std()\n",
    "        df['amount_z_scores'] = (df['log_amount'] - train_stats['log_amount_mean']) / train_stats['log_amount_std']\n",
    "        df['is_outlier_amount'] = (df['amount_z_scores'].abs() > 2).astype(int)\n",
    "        df.drop(columns='amount_z_scores', inplace=True)\n",
    "        \n",
    "        df['amount_bin'], bins = pd.qcut(\n",
    "            df['log_amount'], \n",
    "            q=5, \n",
    "            labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"], \n",
    "            retbins=True\n",
    "        )\n",
    "        train_stats['amount_bins'] = bins\n",
    "\n",
    "        # V-features stats\n",
    "        v_stats = {}\n",
    "        for i in range(1, 29):\n",
    "            col = f\"V{i}\"\n",
    "            v_stats[col] = {\n",
    "                \"mean\": df[col].mean(),\n",
    "                \"std\": df[col].std()\n",
    "            }\n",
    "            z_col = f\"{col}_zscore\"\n",
    "            outlier_col = f\"{col}_is_outlier\"\n",
    "            df[z_col] = (df[col] - v_stats[col][\"mean\"]) / v_stats[col][\"std\"]\n",
    "            df[outlier_col] = (df[z_col].abs() > 2).astype(int)\n",
    "        \n",
    "        # Drop unwanted\n",
    "        cols = [f\"V{i}_is_outlier\" for i in range(1, 29) if i not in [13, 15, 22, 23, 24, 26]]\n",
    "        df.drop(columns=cols, inplace=True)\n",
    "        cols = [f\"V{i}_zscore\" for i in range(1, 29)]\n",
    "        df.drop(columns=cols, inplace=True)\n",
    "\n",
    "        train_stats['v_stats'] = v_stats\n",
    "\n",
    "    # --- if val/test: apply stats from train ---\n",
    "    else:\n",
    "        # Use the provided train_stats directly (don't call compute_train_stats again)\n",
    "        mean = train_stats['log_amount_mean']\n",
    "        std = train_stats['log_amount_std']\n",
    "        df['amount_z_scores'] = (df['log_amount'] - mean) / std\n",
    "        df['is_outlier_amount'] = (df['amount_z_scores'].abs() > 2).astype(int)\n",
    "        df.drop(columns='amount_z_scores', inplace=True)\n",
    "\n",
    "        df['amount_bin'] = pd.cut(\n",
    "            df['log_amount'],\n",
    "            bins=train_stats['amount_bins'],\n",
    "            labels=[\"Very Low\", \"Low\", \"Medium\", \"High\", \"Very High\"],\n",
    "            include_lowest=True\n",
    "        )\n",
    "\n",
    "        for i in range(1, 29):\n",
    "            col = f\"V{i}\"\n",
    "            mean = train_stats['v_stats'][col][\"mean\"]\n",
    "            std = train_stats['v_stats'][col][\"std\"]\n",
    "            z_col = f\"{col}_zscore\"\n",
    "            outlier_col = f\"{col}_is_outlier\"\n",
    "            df[z_col] = (df[col] - mean) / std\n",
    "            df[outlier_col] = (df[z_col].abs() > 2).astype(int)\n",
    "\n",
    "        cols = [f\"V{i}_is_outlier\" for i in range(1, 29) if i not in [13, 15, 22, 23, 24, 26]]\n",
    "        df.drop(columns=cols, inplace=True)\n",
    "        cols = [f\"V{i}_zscore\" for i in range(1, 29)]\n",
    "        df.drop(columns=cols, inplace=True)\n",
    "\n",
    "    # 3. Interactions\n",
    "    df['amount_hour_interaction'] = df['log_amount'] * df['Hour']\n",
    "    df['V7_amount'] = df['V7'] * df['log_amount']\n",
    "    df['V12_amount'] = df['V12'] * df['log_amount']\n",
    "    df['V20_amount'] = df['V20'] * df['log_amount']\n",
    "    df['V11_hour'] = df['V11'] * df['Hour']\n",
    "    df['V12_hour'] = df['V12'] * df['Hour']\n",
    "\n",
    "    return df, train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9212d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_engineered, train_stats = apply_feature_engineering(train)\n",
    "val_engineered,_ = apply_feature_engineering(val,train_stats)\n",
    "test_engineered,_ = apply_feature_engineering(test,train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fc35488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance after sampling: Counter({0: 170579, 1: 170579})\n"
     ]
    }
   ],
   "source": [
    "# --- Custom transformer for cyclic encoding ---\n",
    "class CyclicalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, periods):\n",
    "        self.cols = cols if isinstance(cols, list) else [cols]\n",
    "        self.periods = periods if isinstance(periods, list) else [periods]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col, period in zip(self.cols, self.periods):\n",
    "            sin_col = np.sin(2 * np.pi * X_[col] / period)\n",
    "            cos_col = np.cos(2 * np.pi * X_[col] / period)\n",
    "            X_[f\"{col}_sin\"] = sin_col\n",
    "            X_[f\"{col}_cos\"] = cos_col\n",
    "            X_.drop(columns=[col], inplace=True)  # drop original cyclic col\n",
    "        return X_\n",
    "\n",
    "# --- Features ---\n",
    "X = train_engineered.drop(columns=['Class','Amount'], axis=1)\n",
    "y = train_engineered['Class']\n",
    "\n",
    "cat_feat = ['amount_bin']   \n",
    "bin_feat = [\n",
    "    'V13_is_outlier','V15_is_outlier','V22_is_outlier',\n",
    "    'V23_is_outlier','V24_is_outlier','V26_is_outlier',\n",
    "    'is_outlier_amount','is_rush_hour'\n",
    "] \n",
    "cyc_feat = ['Hour']\n",
    "v_feat = [f\"V{i}\" for i in range(1,29)]\n",
    "num_feat = X.drop(columns=cat_feat+bin_feat+cyc_feat+v_feat, axis=1).columns\n",
    "\n",
    "# --- Preprocessor ---                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "preprocessor = ColumnTransformer([\n",
    "    ('oe', OrdinalEncoder(), cat_feat),\n",
    "    ('scaler', StandardScaler(), num_feat),\n",
    "    ('cyclical', CyclicalFeatures(cols=['Hour'], periods=[24]), cyc_feat)\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "# --- Sampling ---\n",
    "oversample = SMOTE(sampling_strategy='minority', k_neighbors=5, random_state=1)\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
    "\n",
    "# --- Pipeline ---\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('over', oversample),\n",
    "    ('under', undersample),\n",
    "    ('logistic', LogisticRegression())\n",
    "    #('xgboost',XGBClassifier())\n",
    "    #('randomforest',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# --- Fit ---\n",
    "model = pipeline.fit(X, y)\n",
    "\n",
    "# --- Check class balance after resampling ---\n",
    "X_res, y_res = pipeline.named_steps['under'].fit_resample(\n",
    "    *pipeline.named_steps['over'].fit_resample(\n",
    "        preprocessor.fit_transform(X), y\n",
    "    )\n",
    ")\n",
    "print(\"Class balance after sampling:\", Counter(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e2fbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom transformer for cyclic encoding ---\n",
    "class CyclicalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols, periods):\n",
    "        self.cols = cols if isinstance(cols, list) else [cols]\n",
    "        self.periods = periods if isinstance(periods, list) else [periods]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        for col, period in zip(self.cols, self.periods):\n",
    "            sin_col = np.sin(2 * np.pi * X_[col] / period)\n",
    "            cos_col = np.cos(2 * np.pi * X_[col] / period)\n",
    "            X_[f\"{col}_sin\"] = sin_col\n",
    "            X_[f\"{col}_cos\"] = cos_col\n",
    "            X_.drop(columns=[col], inplace=True)  # drop original cyclic col\n",
    "        return X_\n",
    "\n",
    "# --- Features ---\n",
    "X = train_engineered.drop(columns=['Class','Amount'], axis=1)\n",
    "y = train_engineered['Class']\n",
    "\n",
    "cat_feat = ['amount_bin']   \n",
    "bin_feat = [\n",
    "    'V13_is_outlier','V15_is_outlier','V22_is_outlier',\n",
    "    'V23_is_outlier','V24_is_outlier','V26_is_outlier',\n",
    "    'is_outlier_amount','is_rush_hour'\n",
    "] \n",
    "cyc_feat = ['Hour']\n",
    "v_feat = [f\"V{i}\" for i in range(1,29)]\n",
    "num_feat = X.drop(columns=cat_feat+bin_feat+cyc_feat+v_feat, axis=1).columns\n",
    "cnter = Counter(y)\n",
    "ir = cnter[1]/cnter[0]\n",
    "# --- Preprocessor ---                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
    "preprocessor = ColumnTransformer([\n",
    "    ('oe', OrdinalEncoder(), cat_feat),\n",
    "    ('scaler', StandardScaler(), num_feat),\n",
    "    ('cyclical', CyclicalFeatures(cols=['Hour'], periods=[24]), cyc_feat)\n",
    "], remainder='passthrough')\n",
    "\n",
    "\n",
    "\n",
    "# --- Pipeline ---\n",
    "pipeline = imb_Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    #('over', oversample),\n",
    "    #('under', undersample),\n",
    "    ('logistic', LogisticRegression(class_weight={0:ir,1:1}))\n",
    "    #('xgboost',XGBClassifier())\n",
    "    #('randomforest',RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# --- Fit ---\n",
    "model = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "664465c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[165881   4698]\n",
      " [    19    286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    170579\n",
      "           1       0.06      0.94      0.11       305\n",
      "\n",
      "    accuracy                           0.97    170884\n",
      "   macro avg       0.53      0.96      0.55    170884\n",
      "weighted avg       1.00      0.97      0.98    170884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict_proba(X)[:, 1]                                                                                                                                                                                                 \n",
    "y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "# y_pred = model.predict(X)\n",
    "\n",
    "matrix = confusion_matrix(y,y_pred)\n",
    "report = classification_report(y,y_pred)\n",
    "\n",
    "print(matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "968f11c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55377  1493]\n",
      " [   11    79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56870\n",
      "           1       0.05      0.88      0.10        90\n",
      "\n",
      "    accuracy                           0.97     56960\n",
      "   macro avg       0.53      0.93      0.54     56960\n",
      "weighted avg       1.00      0.97      0.99     56960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_val = val_engineered.drop(columns=['Class','Amount'], axis=1)\n",
    "y_val = val_engineered['Class']\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "matrix = confusion_matrix(y_val,y_val_pred)\n",
    "report = classification_report(y_val,y_val_pred)\n",
    "\n",
    "print(matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18a35a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55246  1617]\n",
      " [   10    87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56863\n",
      "           1       0.05      0.90      0.10        97\n",
      "\n",
      "    accuracy                           0.97     56960\n",
      "   macro avg       0.53      0.93      0.54     56960\n",
      "weighted avg       1.00      0.97      0.98     56960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = test_engineered.drop(columns=['Class','Amount'], axis=1)\n",
    "y_test = test_engineered['Class']\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test,y_test_pred)\n",
    "report = classification_report(y_test,y_test_pred)\n",
    "\n",
    "print(matrix)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65971477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
